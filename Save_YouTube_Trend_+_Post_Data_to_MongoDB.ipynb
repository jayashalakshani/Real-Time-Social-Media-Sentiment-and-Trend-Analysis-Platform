{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvJpVRH9mIgOy6BfZoxu+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayashalakshani/Real-Time-Social-Media-Sentiment-and-Trend-Analysis-Platform/blob/main/Save_YouTube_Trend_%2B_Post_Data_to_MongoDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL5nycgSni-O",
        "outputId": "c17711c6-e63b-4ebb-da04-175efee5f0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.164.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.167.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymongo[srv]\n",
            "  Downloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "\u001b[33mWARNING: pymongo 4.12.0 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.69.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.1.31)\n",
            "Downloading google_api_python_client-2.167.0-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=49fccc15648f7260e8f57770c0de1677ff86dd0affde2d89535ea4da0146871a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect, dnspython, pymongo, google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.164.0\n",
            "    Uninstalling google-api-python-client-2.164.0:\n",
            "      Successfully uninstalled google-api-python-client-2.164.0\n",
            "Successfully installed dnspython-2.7.0 google-api-python-client-2.167.0 langdetect-1.0.9 pymongo-4.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade google-api-python-client pymongo[srv] langdetect"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MongoDB Setup"
      ],
      "metadata": {
        "id": "lJQBtGfnqK43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from google.colab import userdata\n",
        "# Replace these with your credentials\n",
        "username = userdata.get('mongodb_username')\n",
        "password = userdata.get('mongodb_pw')\n",
        "cluster_url = \"cluster0.8ad48r1.mongodb.net\""
      ],
      "metadata": {
        "id": "4ONgzltAqKc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full URI\n",
        "uri = f\"mongodb+srv://{username}:{password}@{cluster_url}/?retryWrites=true&w=majority&appName=Cluster0\""
      ],
      "metadata": {
        "id": "FcTyWqjzqOOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to MongoDB Atlas\n",
        "client = MongoClient(uri)"
      ],
      "metadata": {
        "id": "OmUOWG9XqOIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check available databases\n",
        "client.list_database_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGypmlyTqSyt",
        "outputId": "74c35c6f-e7ca-4e16-de99-65b62122973b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['social_media_analytics', 'admin', 'local']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create / select a database and collection\n",
        "db = client[\"social_media_analytics\"]"
      ],
      "metadata": {
        "id": "R_nAnF6eqSrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two collections\n",
        "youtube_sentiment_collection = db[\"youtube_comments\"]\n",
        "youtube_trend_collection = db[\"youtube_tags_data\"]\n",
        "youtube_unique_tag_collection = db[\"youtube_unique_tag\"]"
      ],
      "metadata": {
        "id": "IF12JZ5sqWPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the available collection\n",
        "db.list_collection_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy6JFu0Qqtck",
        "outputId": "6c90cb80-b8a5-4b6b-8d99-41eaf7789075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['youtube_unique_tag',\n",
              " 'youtube_tags_data',\n",
              " 'trend_collection',\n",
              " 'youtube_sentiment_collection',\n",
              " 'sentiment_data']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get trending tags and comments at Youtube"
      ],
      "metadata": {
        "id": "QiAU1jlwqwgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-HtZaXUo1ID",
        "outputId": "c3f40d80-bf7c-4661-ef46-601374792a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Setup API\n",
        "YOUTUBE_API_KEY = userdata.get('YOUTUBE_API_KEY')\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)"
      ],
      "metadata": {
        "id": "bcz8b1QNpGvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
        "\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "c--EHIVXpmrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Fetch Trending Videos"
      ],
      "metadata": {
        "id": "7rsosMLRryMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from langdetect import detect\n",
        "from datetime import datetime\n",
        "\n",
        "def is_english(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False  # In case of error or very short/non-text input\n",
        "\n",
        "def fetch_youtube_trending_tags(db, region='US', max_results=25, top_n_tags=10):\n",
        "    trending_videos = youtube.videos().list(\n",
        "        part=\"snippet\",\n",
        "        chart=\"mostPopular\",\n",
        "        regionCode=region,\n",
        "        maxResults=max_results\n",
        "    ).execute()\n",
        "\n",
        "    tag_counter = Counter()\n",
        "\n",
        "    for video in trending_videos[\"items\"]:\n",
        "        video_id = video[\"id\"]\n",
        "        snippet = video[\"snippet\"]\n",
        "        tags = snippet.get(\"tags\", [])\n",
        "        title = snippet[\"title\"]\n",
        "        published_at = snippet[\"publishedAt\"]\n",
        "\n",
        "        # Save video and its tags\n",
        "        db.youtube_tags_data.insert_one({\n",
        "            \"video_id\": video_id,\n",
        "            \"title\": title,\n",
        "            \"tags\": tags,\n",
        "            \"published_at\": published_at\n",
        "        })\n",
        "\n",
        "        # Count only English tags\n",
        "        for tag in tags:\n",
        "            tag = tag.lower()\n",
        "            if is_english(tag):\n",
        "                tag_counter[tag] += 1\n",
        "\n",
        "    # Get top N trending English tags\n",
        "    top_tags = tag_counter.most_common(top_n_tags)\n",
        "\n",
        "    for tag, _ in top_tags:\n",
        "        db.youtube_unique_tag.insert_one({\n",
        "            \"tag\": tag,\n",
        "            \"fetched_at\": datetime.utcnow()\n",
        "        })\n",
        "\n",
        "    print(f\"✅ Inserted top {top_n_tags} *English* trending tags into 'youtube_unique_tag'\")\n"
      ],
      "metadata": {
        "id": "v2ldd65G1vef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_youtube_trending_tags(db, region=\"US\", max_results=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPnT37jBsU9f",
        "outputId": "0645e254-c839-464d-fd8b-d7853c9eab0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inserted top 10 *English* trending tags into 'youtube_unique_tag'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch Comments for Trending Videos"
      ],
      "metadata": {
        "id": "XmLgX22ksT96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_comments_for_all_tagged_videos(db, min_comments=10, max_videos_per_tag=1):\n",
        "    tag_cursor = db.youtube_unique_tag.find()\n",
        "\n",
        "    for tag_doc in tag_cursor:\n",
        "        tag = tag_doc[\"tag\"]\n",
        "        print(f\"\\n🔍 Searching videos for YouTube tag: #{tag}\")\n",
        "\n",
        "        try:\n",
        "            # Search videos using the tag\n",
        "            search_results = youtube.search().list(\n",
        "                q=tag,\n",
        "                part=\"snippet\",\n",
        "                type=\"video\",\n",
        "                maxResults=max_videos_per_tag\n",
        "            ).execute()\n",
        "\n",
        "            if not search_results[\"items\"]:\n",
        "                print(\"❌ No videos found for this tag.\")\n",
        "                continue\n",
        "\n",
        "            for video in search_results[\"items\"]:\n",
        "                video_id = video[\"id\"][\"videoId\"]\n",
        "                title = video[\"snippet\"][\"title\"]\n",
        "                print(f\"🎥 Selected video: {title} (ID: {video_id})\")\n",
        "\n",
        "                # Fetch comments\n",
        "                comments_collected = 0\n",
        "                next_page_token = None\n",
        "\n",
        "                while comments_collected < min_comments:\n",
        "                    response = youtube.commentThreads().list(\n",
        "                        part=\"snippet\",\n",
        "                        videoId=video_id,\n",
        "                        textFormat=\"plainText\",\n",
        "                        maxResults=100,\n",
        "                        pageToken=next_page_token\n",
        "                    ).execute()\n",
        "\n",
        "                    items = response.get(\"items\", [])\n",
        "                    if not items:\n",
        "                        break\n",
        "\n",
        "                    for item in items:\n",
        "                        if comments_collected >= min_comments:\n",
        "                            break\n",
        "\n",
        "                        comment_info = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "                        comment_text = comment_info[\"textDisplay\"]\n",
        "                        author = comment_info[\"authorDisplayName\"]\n",
        "                        published_at = comment_info[\"publishedAt\"]\n",
        "\n",
        "                        cleaned_text = preprocess_text(comment_text)\n",
        "\n",
        "                        db.youtube_sentiment_collection.insert_one({\n",
        "                            \"video_id\": video_id,\n",
        "                            \"video_title\": title,\n",
        "                            \"tag\": tag,\n",
        "                            \"author\": author,\n",
        "                            \"text\": cleaned_text,\n",
        "                            \"raw_text\": comment_text,\n",
        "                            \"published_at\": published_at\n",
        "                        })\n",
        "\n",
        "                        comments_collected += 1\n",
        "\n",
        "                    next_page_token = response.get(\"nextPageToken\")\n",
        "                    if not next_page_token:\n",
        "                        break\n",
        "\n",
        "                print(f\"✅ Collected {comments_collected} comments for '{title}'\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error fetching comments for tag '{tag}': {str(e)}\")\n"
      ],
      "metadata": {
        "id": "bOlqx4JWscCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_comments_for_all_tagged_videos(db, min_comments=10, max_videos_per_tag=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xis6JCxusl78",
        "outputId": "1e08b267-ead2-420d-c9de-4c2c28ffdfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Searching videos for YouTube tag: #she will\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎥 Selected video: She Will (ID: B5ZQRwrKVjA)\n",
            "❌ Error fetching comments for tag 'she will': <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=B5ZQRwrKVjA&textFormat=plainText&maxResults=100&key=AIzaSyD5z792tRfM92fWnH7mvLKpVnLdXba3DEg&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #hololive production\n",
            "❌ Error fetching comments for tag 'hololive production': 'videoId'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #hololive english\n",
            "🎥 Selected video: Hololive&#39;s Gawr Gura is Quitting #hololive #hololiveenglish #vtuber (ID: bthtAJiE3iE)\n",
            "✅ Collected 10 comments for 'Hololive&#39;s Gawr Gura is Quitting #hololive #hololiveenglish #vtuber'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #inside the nba\n",
            "🎥 Selected video: The Crew Reacts to the Warriors Win Over Memphis 😤 | NBA on TNT (ID: tNsuxrUbOpk)\n",
            "✅ Collected 10 comments for 'The Crew Reacts to the Warriors Win Over Memphis 😤 | NBA on TNT'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #ultimate fighting championship\n",
            "🎥 Selected video: THE BEST FINISHES OF 2024.... so far! 🚨 (ID: JyrYuPwyfQ4)\n",
            "✅ Collected 10 comments for 'THE BEST FINISHES OF 2024.... so far! 🚨'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #paddy the baddy pimblett\n",
            "🎥 Selected video: FIGHT NIGHT VLOG: Unseen Footage From Paddy The Baddy&#39;s STATEMENT WIN at UFC 314 (ID: MkMT5HCjwnU)\n",
            "✅ Collected 10 comments for 'FIGHT NIGHT VLOG: Unseen Footage From Paddy The Baddy&#39;s STATEMENT WIN at UFC 314'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #ufc training\n",
            "🎥 Selected video: Training camp with Coach Khabib 😤 (via nurmagomedov_mma_school/IG) (ID: xmbj-PIpQ4A)\n",
            "✅ Collected 10 comments for 'Training camp with Coach Khabib 😤 (via nurmagomedov_mma_school/IG)'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #fight\n",
            "🎥 Selected video: Gym Fight over a Cable Machine 🤔 💪🏼 Let’s see who Wins 🏆 #fighting #gym #fighter #shorts #viral (ID: BD4HQmczHoo)\n",
            "✅ Collected 10 comments for 'Gym Fight over a Cable Machine 🤔 💪🏼 Let’s see who Wins 🏆 #fighting #gym #fighter #shorts #viral'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #fighter\n",
            "🎥 Selected video: TALI – Fighter (Official Music Video - Eurovision 2024) (ID: DJf04cdgk70)\n",
            "✅ Collected 10 comments for 'TALI – Fighter (Official Music Video - Eurovision 2024)'\n",
            "\n",
            "🔍 Searching videos for YouTube tag: #paddy the baddy next fight\n",
            "🎥 Selected video: UFC 314: Paddy Pimblett vs Michael Chandler Highlights (ID: 7Qudtm702v4)\n",
            "✅ Collected 10 comments for 'UFC 314: Paddy Pimblett vs Michael Chandler Highlights'\n"
          ]
        }
      ]
    }
  ]
}