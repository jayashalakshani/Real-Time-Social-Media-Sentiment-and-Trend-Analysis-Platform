{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Hs6NVXif6Flx0aPA4frFX98oCpy_tgGO","authorship_tag":"ABX9TyOyQE8HvwuGSwTPUevIJapN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Social Media Sentiment Analysis - Speed Layer Implementation\n","## Setup and Dependencies\n","!pip install pyspark pymongo transformers torch nltk pymongo[srv]"],"metadata":{"id":"GNWifnWL8Kvh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","# Social Media Sentiment Analysis - Speed Layer Implementation\n","\n","This script implements the speed layer for a lambda architecture that processes\n","social media data in real-time using Spark Structured Streaming. It analyzes sentiment\n","from Mastodon posts and YouTube comments, and stores the results in MongoDB.\n","\"\"\"\n","\n","# Import required libraries\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime, timedelta\n","import json\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, udf, explode, split, when, lit\n","from pyspark.sql.types import StringType, ArrayType, StructType, StructField, IntegerType, FloatType, TimestampType\n","import pymongo\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","from nltk.tokenize import word_tokenize\n","import nltk"],"metadata":{"id":"_iJC3vTgxXhz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')"],"metadata":{"id":"kjMxUh-Uy-l7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Mount Google Drive to save processed data and models\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"B1Eq6Pu00RIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set project directory\n","PROJECT_DIR = '/content/drive/MyDrive/Colab Notebooks/Sentiment Analysis'\n","os.makedirs(PROJECT_DIR, exist_ok=True)"],"metadata":{"id":"7MpW6B5w1BD4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Initialize Spark Session with Streaming configurations\n","spark = SparkSession.builder \\\n","    .appName(\"SentimentAnalysisSpeedLayer\") \\\n","    .config(\"spark.driver.memory\", \"12g\") \\\n","    .config(\"spark.executor.memory\", \"4g\") \\\n","    .config(\"spark.sql.streaming.schemaInference\", \"true\") \\\n","    .getOrCreate()\n","\n","print(f\"Spark version: {spark.version}\")"],"metadata":{"id":"7cZmJQT94xpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## MongoDB Connection\n","from google.colab import userdata\n","# Get credentials secret keys\n","username = userdata.get('mongodb_username')\n","password = userdata.get('mongodb_pw')\n","cluster_url = \"cluster0.8ad48r1.mongodb.net\"\n","MONGO_CONNECTION_STRING = f\"mongodb+srv://{username}:{password}@{cluster_url}/?retryWrites=true&w=majority&appName=Cluster0\"\n","\n","def connect_to_mongodb():\n","    \"\"\"Connect to MongoDB and return the database client.\"\"\"\n","    try:\n","        client = pymongo.MongoClient(MONGO_CONNECTION_STRING)\n","        print(\"Connected to MongoDB successfully!\")\n","        return client\n","    except Exception as e:\n","        print(f\"Failed to connect to MongoDB: {e}\")\n","        return None\n","\n","mongo_client = connect_to_mongodb()\n","# Create the new database for speed layer outputs\n","db = mongo_client[\"social_media_analytics_new\"] if mongo_client else None"],"metadata":{"id":"igylxr6R6Dfh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["db.list_collection_names()"],"metadata":{"id":"qZwJS8VoqEuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data_from_mongodb():\n","    \"\"\"Load data from MongoDB collections into PySpark DataFrames.\"\"\"\n","\n","    # Create schema for Mastodon data\n","    mastodon_schema = StructType([\n","        StructField(\"tag\", StringType(), True),\n","        StructField(\"text\", StringType(), True),\n","        StructField(\"created_at\", TimestampType(), True),\n","        StructField(\"post_url\", StringType(), True)\n","    ])\n","\n","    # Create schema for YouTube data\n","    youtube_schema = StructType([\n","        StructField(\"tag\", StringType(), True),\n","        StructField(\"text\", StringType(), True),\n","        StructField(\"published_at\", StringType(), True),\n","        StructField(\"video_id\", StringType(), True),\n","        StructField(\"video_title\", StringType(), True)\n","    ])\n","\n","    # Load Mastodon data\n","    mastodon_data = []\n","    if db is not None:  # Changed from 'if db' to 'if db is not None'\n","        for doc in db.mastodon_sentiment_data.find():\n","            mastodon_data.append(doc)\n","\n","    # Load YouTube data\n","    youtube_data = []\n","    if db is not None:  # Changed from 'if db' to 'if db is not None'\n","        for doc in db.youtube_sentiment_data.find():\n","            youtube_data.append(doc)\n","\n","    # Create PySpark DataFrames\n","    mastodon_df = spark.createDataFrame(mastodon_data, schema=mastodon_schema) if mastodon_data else None\n","    youtube_df = spark.createDataFrame(youtube_data, schema=youtube_schema) if youtube_data else None\n","\n","    return mastodon_df, youtube_df"],"metadata":{"id":"ls9t9kvU6wQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the data\n","mastodon_df, youtube_df = load_data_from_mongodb()\n","\n","if mastodon_df:\n","    print(f\"Loaded {mastodon_df.count()} Mastodon posts\")\n","    mastodon_df.printSchema()\n","    mastodon_df.show(5, truncate=True)\n","\n","if youtube_df:\n","    print(f\"Loaded {youtube_df.count()} YouTube comments\")\n","    youtube_df.printSchema()\n","    youtube_df.show(5, truncate=True)"],"metadata":{"id":"jZWDr2uYqO7l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Data Preprocessing\n","def preprocess_mastodon_data(df):\n","    \"\"\"Preprocess Mastodon data.\"\"\"\n","    if df is None:\n","        return None\n","\n","    # Convert timestamp to date format\n","    df = df.withColumn(\"date\", col(\"created_at\").cast(\"date\"))\n","\n","    # Clean content: Remove HTML tags, URLs, etc.\n","    clean_content_udf = udf(lambda x: clean_text(x), StringType())\n","    df = df.withColumn(\"clean_content\", clean_content_udf(col(\"text\")))\n","\n","    # Filter out empty content\n","    df = df.filter(col(\"clean_content\").isNotNull() & (col(\"clean_content\") != \"\"))\n","\n","    return df\n","\n","def preprocess_youtube_data(df):\n","    \"\"\"Preprocess YouTube data.\"\"\"\n","    if df is None:\n","        return None\n","\n","    # Convert publishedAt to date format\n","    df = df.withColumn(\"date\", col(\"published_at\").cast(\"date\"))\n","\n","    # Clean comment text\n","    clean_comment_udf = udf(lambda x: clean_text(x), StringType())\n","    df = df.withColumn(\"clean_commentText\", clean_comment_udf(col(\"text\")))\n","\n","    # Filter out empty comments\n","    df = df.filter(col(\"clean_commentText\").isNotNull() & (col(\"clean_commentText\") != \"\"))\n","\n","    return df\n","\n","def clean_text(text):\n","    \"\"\"Clean text by removing unwanted characters, HTML tags, links, etc.\"\"\"\n","    if not text:\n","        return None\n","\n","    import re\n","    # Remove HTML tags\n","    text = re.sub(r'<.*?>', '', text)\n","    # Remove URLs\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n","    # Remove mentions\n","    text = re.sub(r'@\\w+', '', text)\n","    # Remove hashtag symbols but keep the text\n","    text = re.sub(r'#', '', text)\n","    # Remove special characters\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # Remove extra whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text if text else None"],"metadata":{"id":"KSK-sm5y7Sbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process the data\n","processed_mastodon_df = preprocess_mastodon_data(mastodon_df)\n","processed_mastodon_df.show(5)\n","processed_youtube_df = preprocess_youtube_data(youtube_df)\n","processed_youtube_df.show(5)"],"metadata":{"id":"1sm10kHBqbL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if processed_mastodon_df:\n","    print(\"Processed Mastodon data:\")\n","    processed_mastodon_df.select(\"tag\", \"clean_content\", \"date\").show(5, truncate=True)\n","\n","if processed_youtube_df:\n","    print(\"Processed YouTube data:\")\n","    processed_youtube_df.select(\"tag\", \"clean_commentText\", \"date\").show(5, truncate=True)"],"metadata":{"id":"byKbL7FIqm5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Sentiment Analysis Model\n","def load_sentiment_model():\n","    \"\"\"Load a pre-trained sentiment analysis model.\"\"\"\n","    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","    return tokenizer, model\n","\n","tokenizer, model = load_sentiment_model()"],"metadata":{"id":"vKr2GrL67_IF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_sentiment_transformers(text, tokenizer=tokenizer, model=model, max_length=512):\n","    \"\"\"Analyze sentiment using Transformers.\"\"\"\n","    if not text:\n","        return None\n","\n","    # Truncate text if needed\n","    if len(text) > max_length * 4:  # rough character estimate\n","        text = text[:max_length * 4]\n","\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n","        sentiment_id = torch.argmax(scores).item()\n","\n","    # Map sentiment ID to label (specific to the model)\n","    id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","    sentiment = id2label[sentiment_id]\n","\n","    return sentiment"],"metadata":{"id":"jfwPTWhz836U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Register UDFs for data processing\n","sentiment_transformers_udf = udf(analyze_sentiment_transformers, StringType())"],"metadata":{"id":"zW01yRqf9jy5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply sentiment analysis to Mastodon data\n","if processed_mastodon_df:\n","    mastodon_with_sentiment = processed_mastodon_df.withColumn(\n","        \"sentiment\", sentiment_transformers_udf(col(\"clean_content\"))\n","    )\n","\n","    print(\"Mastodon data with sentiment:\")\n","    mastodon_with_sentiment.select(\"clean_content\", \"sentiment\").show(5, truncate=True)\n","\n","# Apply sentiment analysis to YouTube data\n","if processed_youtube_df:\n","    youtube_with_sentiment = processed_youtube_df.withColumn(\n","        \"sentiment\", sentiment_transformers_udf(col(\"clean_commentText\"))\n","    )\n","\n","    print(\"YouTube data with sentiment:\")\n","    youtube_with_sentiment.select(\"clean_commentText\", \"sentiment\").show(5, truncate=True)"],"metadata":{"id":"pAXKNeMxq7ie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mastodon_with_sentiment.show(5)"],"metadata":{"id":"2FC8vYsouAJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create streaming sources from MongoDB for Mastodon and YouTube data\n","def create_streaming_sources():\n","    \"\"\"Create streaming sources that continuously pull data from MongoDB collections.\"\"\"\n","\n","    # Setup MongoDB connection options for Spark\n","    mongo_options = {\n","        \"uri\": MONGO_CONNECTION_STRING,\n","        \"database\": \"social_media_analytics\",\n","        \"collection\": \"mastodon_sentiment_data\",\n","    }\n","\n","    # Stream Mastodon data\n","    mastodon_stream = spark \\\n","        .readStream \\\n","        .format(\"mongodb\") \\\n","        .options(**mongo_options) \\\n","        .load()\n","\n","    # Update options for YouTube data\n","    mongo_options[\"collection\"] = \"youtube_sentiment_data\"\n","\n","    # Stream YouTube data\n","    youtube_stream = spark \\\n","        .readStream \\\n","        .format(\"mongodb\") \\\n","        .options(**mongo_options) \\\n","        .load()\n","\n","    return mastodon_stream, youtube_stream"],"metadata":{"id":"dwPydNYo-FGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Aggregate and Analyze Results\n","from pyspark.sql.functions import col, explode, to_date\n","import pandas as pd\n","\n","def analyze_sentiment_by_platform(mastodon_df=None, youtube_df=None):\n","    \"\"\"Analyze sentiment distribution by platform, including platform type.\"\"\"\n","    results = []\n","\n","    # Mastodon sentiment distribution\n","    if mastodon_df is not None:\n","        print(\"Processing Mastodon sentiment distribution...\")\n","        mastodon_sentiment_counts = mastodon_df.groupBy(\"sentiment\").count().toPandas()\n","        if not mastodon_sentiment_counts.empty:\n","            mastodon_sentiment_counts['platform'] = 'mastodon'\n","            results.extend(mastodon_sentiment_counts[['platform', 'sentiment', 'count']].to_dict('records'))\n","        else:\n","            print(\"No Mastodon sentiment data found\")\n","    else:\n","        print(\"Mastodon DataFrame is None\")\n","\n","    # YouTube sentiment distribution\n","    if youtube_df is not None:\n","        print(\"Processing YouTube sentiment distribution...\")\n","        youtube_sentiment_counts = youtube_df.groupBy(\"sentiment\").count().toPandas()\n","        if not youtube_sentiment_counts.empty:\n","            youtube_sentiment_counts['platform'] = 'youtube'\n","            results.extend(youtube_sentiment_counts[['platform', 'sentiment', 'count']].to_dict('records'))\n","        else:\n","            print(\"No YouTube sentiment data found\")\n","    else:\n","        print(\"YouTube DataFrame is None\")\n","\n","    return results\n","\n","\n","def analyze_sentiment_over_time(mastodon_df=None, youtube_df=None):\n","    \"\"\"Analyze sentiment trends over time, including platform type.\"\"\"\n","    results = []\n","\n","    # Mastodon sentiment over time\n","    if mastodon_df is not None:\n","        print(\"Processing Mastodon sentiment over time...\")\n","        mastodon_df = mastodon_df.withColumn(\"date\", to_date(col(\"created_at\"))).withColumn(\"platform\", lit(\"mastodon\"))\n","        mastodon_time_trends = mastodon_df.groupBy(\"platform\", \"date\", \"sentiment\").count().toPandas()\n","        if not mastodon_time_trends.empty:\n","            results.append(mastodon_time_trends)\n","        else:\n","            print(\"No Mastodon time trend data found\")\n","    else:\n","        print(\"Mastodon DataFrame is None\")\n","\n","    # YouTube sentiment over time\n","    if youtube_df is not None:\n","        print(\"Processing YouTube sentiment over time...\")\n","        youtube_df = youtube_df.withColumn(\"date\", to_date(col(\"published_at\"))).withColumn(\"platform\", lit(\"youtube\"))\n","        youtube_time_trends = youtube_df.groupBy(\"platform\", \"date\", \"sentiment\").count().toPandas()\n","        if not youtube_time_trends.empty:\n","            results.append(youtube_time_trends)\n","        else:\n","            print(\"No YouTube time trend data found\")\n","    else:\n","        print(\"YouTube DataFrame is None\")\n","\n","    # Combine results into a single DataFrame\n","    if results:\n","        return pd.concat(results, ignore_index=True)\n","    return pd.DataFrame()\n","\n","def analyze_sentiment_by_tag(mastodon_df=None):\n","    \"\"\"Analyze sentiment by tag (for Mastodon), including platform type.\"\"\"\n","    if mastodon_df is None:\n","        print(\"Mastodon DataFrame is None\")\n","        return None\n","\n","    print(\"Processing Mastodon sentiment by tag...\")\n","    # Add platform column\n","    mastodon_df = mastodon_df.withColumn(\"platform\", lit(\"mastodon\"))\n","    tag_sentiment = mastodon_df.groupBy(\"platform\", \"tag\", \"sentiment\").count()\n","\n","    # Get the most common tags\n","    top_tags = mastodon_df.groupBy(\"tag\").count().orderBy(col(\"count\").desc()).limit(20).toPandas()\n","\n","    if not top_tags.empty:\n","        top_tag_list = top_tags[\"tag\"].tolist()\n","        top_tag_sentiment = tag_sentiment.filter(col(\"tag\").isin(top_tag_list)).toPandas()\n","        if not top_tag_sentiment.empty:\n","            return top_tag_sentiment\n","        else:\n","            print(\"No sentiment data for top tags\")\n","            return None\n","    else:\n","        print(\"No tags found in Mastodon data\")\n","        return None"],"metadata":{"id":"JYiAWzNstG6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the analyses\n","platform_sentiment = analyze_sentiment_by_platform(mastodon_with_sentiment, youtube_with_sentiment)\n","time_sentiment = analyze_sentiment_over_time(mastodon_with_sentiment, youtube_with_sentiment)\n","tag_sentiment = analyze_sentiment_by_tag(mastodon_with_sentiment)"],"metadata":{"id":"4R8ZzcX4tSMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, to_timestamp, date_format, lit\n","# Extract time from timestamp in Spark\n","youtube_df = youtube_with_sentiment.withColumn(\"time\", date_format(to_timestamp(\"published_at\"), \"hh:mm:ss a\")) \\\n","    .withColumn(\"Platform\", lit(\"youtube\")) \\\n","    .withColumnRenamed(\"clean_commentText\", \"clean_content\") \\\n","    .select(\"Platform\", \"tag\", \"time\", \"date\", \"clean_content\", \"sentiment\")\n","\n","mastodon_df = mastodon_with_sentiment.withColumn(\"time\", date_format(to_timestamp(\"created_at\"), \"hh:mm:ss a\")) \\\n","    .withColumn(\"Platform\", lit(\"mastodon\")) \\\n","    .select(\"Platform\", \"tag\", \"time\", \"date\", \"clean_content\", \"sentiment\")\n","\n","# Combine both Spark DataFrames\n","combined_spark_df = mastodon_df.unionByName(youtube_df)\n","\n","# Convert to Pandas for display or export\n","combined_df = combined_spark_df.toPandas()\n","\n","\n","# Preview the final DataFrame\n","print(combined_df.head())"],"metadata":{"id":"OnacAtTYu2oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Save Processed Data for Serving Layer\n","batch_platform_sentiment = db['batch_platform_sentiment']\n","batch_tag_sentiment = db['batch_tag_sentiment']\n","combined_sentiment = db['combined_sentiment']"],"metadata":{"id":"RWrekuIKxjdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","\n","def save_to_mongodb():\n","    \"\"\"Save processed data back to MongoDB for the serving layer.\"\"\"\n","    if db is None:\n","        print(\"MongoDB connection not available. Cannot save results.\")\n","        return\n","\n","    try:\n","        # Save platform sentiment distribution\n","        if platform_sentiment:\n","            print(\"Saving platform sentiment:\", platform_sentiment)\n","            db.batch_platform_sentiment.delete_many({})\n","            db.batch_platform_sentiment.insert_one({\n","                \"timestamp\": datetime.now(),\n","                \"data\": platform_sentiment\n","            })\n","            print(\"✅ Saved platform sentiment distribution to MongoDB.\")\n","        else:\n","            print(\"No platform sentiment data to save.\")\n","\n","        # Save tag sentiment analysis\n","        if tag_sentiment is not None and not tag_sentiment.empty:\n","            print(\"Saving tag sentiment:\", tag_sentiment)\n","            tag_data = tag_sentiment.to_dict('records')\n","            db.batch_tag_sentiment.delete_many({})\n","            db.batch_tag_sentiment.insert_one({\n","                \"timestamp\": datetime.now(),\n","                \"data\": tag_data\n","            })\n","            print(\"✅ Saved tag sentiment analysis to MongoDB.\")\n","        else:\n","            print(\"No tag sentiment data to save.\")\n","\n","        # Save combined sentiment data\n","        if combined_df is not None and not combined_df.empty:\n","            print(\"Saving combined sentiment data...\")\n","\n","            # Convert date to string to avoid BSON encoding error\n","            combined_df['date'] = combined_df['date'].astype(str)\n","\n","            db.combined_sentiment.delete_many({})  # Clears old data\n","            db.combined_sentiment.insert_many(combined_df.to_dict(\"records\"))\n","\n","            print(\"✅ Combined sentiment data inserted into MongoDB.\")\n","        else:\n","            print(\"No combined sentiment data to save.\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error saving to MongoDB: {str(e)}\")\n"],"metadata":{"id":"yL0RGL4EBIHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save results\n","save_to_mongodb()"],"metadata":{"id":"08jxNqSFxn8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Cleanup and Close Connections\n","\n","# Close MongoDB connection\n","if mongo_client:\n","    mongo_client.close()\n","    print(\"Closed MongoDB connection.\")\n","\n","# Stop Spark session\n","spark.stop()\n","print(\"Stopped Spark session.\")\n","\n","print(\"\\nSpeed Layer processing completed successfully!\")"],"metadata":{"id":"OtdKiln2CA-k"},"execution_count":null,"outputs":[]}]}